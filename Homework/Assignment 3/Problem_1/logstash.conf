input {
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["entity_counts"]
    group_id => "logstash_group"
    auto_offset_reset => "earliest"
    codec => json {}
  }
}
filter {
  # (No additional filtering needed; events already in JSON with fields entity, count, timestamp)
}
output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "news_entities"
    # You could set document_id => "%{entity}" to upsert by entity, but here we treat each update as a new time-series entry.
  }
  stdout { codec => rubydebug }
}
